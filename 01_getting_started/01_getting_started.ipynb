{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3844b1c5",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "- [Introduction - OpenAI API](https://platform.openai.com/docs/introduction/overview)\n",
    "- [API Reference - OpenAI API (NodeJS)](https://platform.openai.com/docs/api-reference/introduction?lang=node.js)\n",
    "- [openai/openai-node: Node.js library for the OpenAI API](https://github.com/openai/openai-node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71e00e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d885845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nikolausbrunner/.zshenv\n"
     ]
    }
   ],
   "source": [
    "dotenv_path = os.path.expanduser(\"~/.zshenv\")\n",
    "print(dotenv_path)\n",
    "config = dotenv_values(dotenv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e505370d",
   "metadata": {},
   "source": [
    "## Tokens\n",
    "\n",
    "The GPT family of models process text using tokens, which are common sequences of characters found in text. The models understand the statistical relationships between these tokens, and excel at producing the next token in a sequence of tokens.\n",
    "\n",
    "> A helpful rule of thumb is that one token generally corresponds to ~4 characters of text for common English text. This translates to roughly Â¾ of a word (so 100 tokens ~= 75 words).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64f87bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"\\n\\n1. Tokyo, Japan\\n2. Delhi, India\\n3. Shanghai, China\\n4. Sao Paulo, Brazil\\n5. Mexico City, Mexico\\n6. Cairo, Egypt\\n7. Mumbai, India\\n8. Dhaka, Bangladesh\\n9. New York City, United States\\n10. Los Angeles, United States\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1682262353,\n",
      "  \"id\": \"cmpl-78VZhcU3d5KaG6ZeLjGAvxtWQh7sQ\",\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 69,\n",
      "    \"prompt_tokens\": 8,\n",
      "    \"total_tokens\": 77\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    prompt = \"The top 10 most populated cities are:\",\n",
    "    engine = \"text-davinci-003\",\n",
    "    max_tokens = 200\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dcd7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
